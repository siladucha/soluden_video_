# Video Analysis System

## ğŸ“Œ Overview
This project is an **Demo AI-powered video analysis system** that combines **object detection** and **scene captioning** to automatically generate detailed descriptions of video content. It uses **YOLO** for object detection and **BLIP-2** for natural language scene descriptions.

## ğŸš€ Features
- **ğŸ¯ Object Detection** â€“ Uses YOLOv8 models to identify and track objects in video frames
- **ğŸ“ Scene Captioning** â€“ Generates natural language descriptions using BLIP-2 vision-language model
- **â±ï¸ Timeline Analysis** â€“ Creates detailed chronological breakdown of video scenes
- **ğŸ“Š Object Statistics** â€“ Counts and analyzes object frequency throughout the video
- **ğŸ”§ Configurable Modes** â€“ Three performance modes: fast, balanced, and accurate
- **ï¿½ FJSON Export** â€“ Saves analysis results in structured JSON format
- **ï¿½ï¸ Smuart Processing** â€“ Automatic device detection (MPS/CPU) and memory optimization

## ğŸ—ï¸ System Architecture
The system processes videos through a pipeline approach:

1ï¸âƒ£ **Frame Sampling** â€“ Intelligently samples frames based on motion detection
2ï¸âƒ£ **Object Detection** â€“ YOLOv8 identifies objects with confidence scoring
3ï¸âƒ£ **Scene Understanding** â€“ BLIP-2 generates contextual descriptions
4ï¸âƒ£ **Timeline Generation** â€“ Creates chronological analysis with timestamps
5ï¸âƒ£ **Statistics & Export** â€“ Aggregates data and exports results

## ğŸ› ï¸ Installation & Setup
### **Prerequisites**
- **Python 3.8+**
- **PyTorch** with MPS support (for Apple Silicon) or CUDA (for NVIDIA GPUs)

### **Install Required Packages**
```bash
pip install -r requirements.txt
```

### **Dependencies**
- `ultralytics` - YOLOv8 object detection
- `transformers` - BLIP-2 vision-language model
- `opencv-python` - Video processing
- `torch` - Deep learning framework
- `pillow` - Image processing
- `tqdm` - Progress bars
- `numpy` - Numerical computing

## ğŸš€ Usage

### **Basic Usage**
```bash
python video_to_text.py path/to/video.mp4
```

### **With Output File**
```bash
python video_to_text.py path/to/video.mp4 -o analysis.json
```

### **Performance Modes**
```bash
# Fast mode - Quick processing, basic object detection only
python video_to_text.py video.mp4 -m fast

# Balanced mode - Good balance of speed and accuracy (default)
python video_to_text.py video.mp4 -m balanced

# Accurate mode - Maximum accuracy, slower processing
python video_to_text.py video.mp4 -m accurate
```

### **Handling Files with Spaces**
```bash
python video_to_text.py "path/to/My Video File.mp4" -m balanced
```

## âš™ï¸ Configuration Modes

| Mode | YOLO Model | BLIP-2 | Sample Rate | Resolution | Use Case |
|------|------------|--------|-------------|------------|----------|
| **Fast** | YOLOv8n | None | 30% | 320px | Quick object detection |
| **Balanced** | YOLOv8m | BLIP-2 2.7B | 50% | 480px | General purpose analysis |
| **Accurate** | YOLOv8x | BLIP-2 2.7B | 100% | 640px | Detailed analysis |

## ğŸ“Š Output Format
The system generates detailed analysis including:

### **Console Output**
```
Ğ”Ğ»Ğ¸Ñ‚ĞµĞ»ÑŒĞ½Ğ¾ÑÑ‚ÑŒ: 02:15 | ĞšĞ°Ğ´Ñ€Ğ¾Ğ²: 3240 | ĞĞ±Ñ€Ğ°Ğ±Ğ¾Ñ‚Ğ°ĞµĞ¼: 67
=== ĞŸĞ¾Ğ´Ñ€Ğ¾Ğ±Ğ½Ğ°Ñ Ñ…Ñ€Ğ¾Ğ½Ğ¾Ğ»Ğ¾Ğ³Ğ¸Ñ ÑÑ†ĞµĞ½ ===
00:05 â€” A person walking in a park with trees in the background (Ğ¾Ğ±ÑŠĞµĞºÑ‚Ñ‹: person(1), tree(3))
00:12 â€” A car driving on a street with buildings visible (Ğ¾Ğ±ÑŠĞµĞºÑ‚Ñ‹: car(1), building(2))
```

### **JSON Export Structure**
```json
{
  "summary": "Ğ’Ğ¸Ğ´ĞµĞ¾ 02:15 Ñ Ğ¾Ğ±ÑŠĞµĞºÑ‚Ğ°Ğ¼Ğ¸: person, car, tree, building",
  "timeline": [
    {
      "time": "00:05",
      "caption": "A person walking in a park with trees in the background",
      "objects": ["person", "tree", "tree", "tree"]
    }
  ],
  "objects": {
    "person": 15,
    "car": 8,
    "tree": 45,
    "building": 12
  }
}
```

## ğŸ”§ Technical Details

### **Smart Frame Sampling**
- Motion-based frame selection to avoid redundant processing
- Configurable sampling rates based on performance mode
- Automatic duplicate frame detection and skipping

### **Memory Optimization**
- Automatic memory cleanup every 50 frames
- MPS cache clearing for Apple Silicon devices
- Efficient batch processing for large videos

### **Device Support**
- **Apple Silicon**: Automatic MPS acceleration
- **NVIDIA GPUs**: CUDA support
- **CPU Fallback**: Works on any system

## ğŸ¯ Use Cases
- **Content Analysis** â€“ Automatic video content categorization and tagging
- **Accessibility** â€“ Generate descriptions for visually impaired users
- **Video Search** â€“ Create searchable metadata from video content
- **Security Analysis** â€“ Automated surveillance video analysis
- **Media Production** â€“ Content review and scene breakdown

## ğŸ“œ License
This project is licensed under the **MIT License**.

## ğŸ‘¨â€ğŸ’» Development
The system follows a modular architecture with clear separation of concerns:
- Object detection pipeline using YOLOv8
- Scene captioning with BLIP-2 transformer models
- Efficient video processing with OpenCV
- Smart memory management and device optimization